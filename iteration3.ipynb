{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qfbuPkS8RXWaufAN3lTDmzMyQOvYSvax",
      "authorship_tag": "ABX9TyOrlqTylti7gjAHozKar+c3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARSBros3/fun_coding_stuff/blob/main/iteration3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "i6b_mtq8gigL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "232093dd-1f7e-4ae0-8c58-78bdd3ee5b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.24)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.26)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.8)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (3.7.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Please ask a question, or type end to stop.What is the capital of the USA\n",
            "san diego\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f19c0affb283>\u001b[0m in \u001b[0;36m<cell line: 125>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please ask a question, or type end to stop.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ok, thank you!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "!pip install pymongo \"pymongo[srv]\" langchain transformers accelerate\n",
        "# !pip install cchardet\n",
        "import os\n",
        "import cchardet\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "import re\n",
        "from langchain.chains import LLMChain, ConstitutionalChain\n",
        "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain import HuggingFaceHub\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "import accelerate\n",
        "\n",
        "from google.colab import userdata\n",
        "uri = f\"mongodb+srv://sridharananish5:{userdata.get('mongo_pw')}@cluster0.t8s7xp5.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "#mongo_pw hidden for security purposes.\n",
        "\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "db = client[\"un_database\"] #the database name\n",
        "all_speeches = db[\"all_speeches\"] #the table name\n",
        "\n",
        "# Path to the \"master\" folder with the full corpus in .txt files.\n",
        "master_folder_path = \"/content/drive/MyDrive/TXT\"\n",
        "\n",
        "# Use the code below to repopulate the MongoDB database.\n",
        "\n",
        "'''\n",
        "\n",
        "all_speeches.drop()\n",
        "#every runtime the columns get added and may be repeated, so we are deleting and starting anew.\n",
        "\n",
        "all_speeches = db[\"all_speeches\"] #creating anew\n",
        "\n",
        "# The \"master\" folder has multiple folders for each session.\n",
        "for session_folder in os.listdir(master_folder_path):\n",
        "  session_folder_path = os.path.join(master_folder_path, session_folder)\n",
        "\n",
        "  if os.path.isdir(session_folder_path):\n",
        "    # Each folder name is of the form \"Session xx - yyyy\" where xx is the session number and yyyy is the year.\n",
        "    session_info = session_folder.split(\"-\")\n",
        "    session_number = session_info[0].strip().split()[-1]\n",
        "    year = session_info[1]\n",
        "\n",
        "    # Each session folder has multiple .txt files for each speech.\n",
        "    for text_file in os.listdir(session_folder_path):\n",
        "      if text_file.endswith(\".txt\"):\n",
        "\n",
        "        #some corrupted files with macOS metadata that always start with \"._\" showed up in the corpus. skipping.\n",
        "        if text_file.startswith(\"._\"):\n",
        "          continue\n",
        "\n",
        "        # each file name is of the form \"ccc_xx_yyyy.txt\" where ccc is the country code.\n",
        "        country_code = text_file.split(\"_\")[0]\n",
        "        text_file_path = os.path.join(session_folder_path, text_file)\n",
        "\n",
        "        # Not every text file has the same encoding. Using chardet.\n",
        "        with open(text_file_path,\"rb\") as f:\n",
        "          result=cchardet.detect(f.read())\n",
        "\n",
        "        with open(text_file_path,\"r\",encoding=result[\"encoding\"]) as f:\n",
        "          file_content = f.read()\n",
        "\n",
        "        # Insert into our table.\n",
        "        all_speeches.insert_one({\n",
        "            \"year\": year,\n",
        "            \"session_number\": session_number,\n",
        "            \"country_code\": country_code,\n",
        "            \"raw_text\": file_content\n",
        "            })\n",
        "'''\n",
        "# use this code to preprocess the dataset for use to train llm.\n",
        "\n",
        "'''\n",
        "# database ready! time to train llm on it.\n",
        "# columns- year of speech, UN session number, country code for the speaker, raw text of the speech.\n",
        "\n",
        "speeches = all_speeches.find()\n",
        "training_data = []\n",
        "\n",
        "for speech in speeches:\n",
        "    year = speech['year']\n",
        "    session_no = speech['session_number']\n",
        "    country = speech['country_code']\n",
        "    text = speech['raw_text']\n",
        "\n",
        "    # Preprocess the text- remove spl chars, lowercase\n",
        "    processed_text = re.sub(r'\\W+', ' ', text)  # Remove non-alphanumeric characters\n",
        "    processed_text = processed_text.lower()\n",
        "\n",
        "    # Create a training example\n",
        "    training_example = f\"this speech was made by the representative of the country with country code {country.lower()} in the year {year} during the un general debate s session number {session_no} {processed_text}\"\n",
        "    training_data.append(training_example)\n",
        "\n",
        "# training data ready!\n",
        "\n",
        "\n",
        "# dataset tokenising\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
        "tokenized_dataset = tokenizer(training_data, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "# create PyTorch dataset\n",
        "input_ids = tokenized_dataset[\"input_ids\"]\n",
        "attention_masks = tokenized_dataset[\"attention_mask\"]\n",
        "dataset = torch.utils.data.TensorDataset(input_ids, attention_masks)\n",
        "torch.save(dataset, \"preprocessed_dataset.pt\")\n",
        "\n",
        "'''\n",
        "\n",
        "train_dataset = torch.load(\"/content/preprocessed_dataset.pt\")\n",
        "\n",
        "qa_prompt = PromptTemplate(\n",
        "    template=\"Q: {question} A:\",\n",
        "    input_variables=[\"question\"],\n",
        ")\n",
        "\n",
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-small\",huggingfacehub_api_token=\"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\", model_kwargs={\"temperature\":0.1})\n",
        "\n",
        "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
        "\n",
        "question=\"\"\n",
        "\n",
        "while question!=\"end\":\n",
        "  question=input(\"Please ask a question, or type end to stop.\")\n",
        "  if question==\"end\":\n",
        "    print(\"Ok, thank you!\")\n",
        "  else:\n",
        "    print(qa_chain.invoke({\"question\":question})[\"text\"])"
      ]
    }
  ]
}