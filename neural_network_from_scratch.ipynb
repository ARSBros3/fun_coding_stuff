{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Neural Network From Scratch.\n",
    "Here, I am building a Neural Network from scratch using only numpy. It's an interesting challenge, so why not? :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin with an introductory dataset- the MNIST handwritten digit dataset. It's the hello world for CV!\n",
    "\n",
    "The dataset is downloaded from Kaggle at https://www.kaggle.com/competitions/digit-recognizer/data.\n",
    "\n",
    "They have already done the data collection and preprocessing to get a dataset of 784 (28*28) grayscale values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to prevent the chance of data being trained too well on the training dataset and not being able to generalise, I need to split it into training and test datasets.\n",
    "\n",
    "First, I will store the dataset as a numpy array for the rest of the code. Then, I will shuffle up the rows. Lastly, let's store the training labels (or \"answers\") in y_train, y_test respectively, and the 784 pixel values for the images as x_train, x_test respectively.\n",
    "\n",
    "For convenience while coding, I will work with the transpose of the values.\n",
    "\n",
    "To decide how much to set aside for testing, I will take a fraction of the dataset, and the fraction can be arbitrary (for now, 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "num_instances, pixels_plus_one = data.shape\n",
    "num_pixels = pixels_plus_one - 1\n",
    "\n",
    "test_instances = int(num_instances * 0.2)\n",
    "\n",
    "test_data = data[:test_instances].T\n",
    "x_test = test_data[1:]\n",
    "y_test = test_data[0]\n",
    "\n",
    "train_data = data[test_instances:].T\n",
    "x_train = train_data[1:]\n",
    "y_train = train_data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
